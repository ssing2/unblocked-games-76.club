#!/usr/bin/env python3
"""
æ‰¹é‡åˆ é™¤HTMLæ–‡ä»¶ä¸­çš„keywords metaæ ‡ç­¾
"""

import os
import re
import glob

def remove_keywords_meta_tag(file_path):
    """ä»HTMLæ–‡ä»¶ä¸­åˆ é™¤keywords metaæ ‡ç­¾"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # åŒ¹é…keywords metaæ ‡ç­¾çš„æ­£åˆ™è¡¨è¾¾å¼ï¼ˆåŒ…æ‹¬æ¢è¡Œç¬¦ï¼‰
        pattern = r'\s*<meta\s+name=["\']keywords["\']\s+content=["\'][^"\']*["\']\s*>\s*\n?'
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«keywordsæ ‡ç­¾
        if re.search(pattern, content, re.IGNORECASE):
            # åˆ é™¤keywordsæ ‡ç­¾
            new_content = re.sub(pattern, '', content, flags=re.IGNORECASE)
            
            # å†™å›æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(new_content)
            
            return True
        return False
    except Exception as e:
        print(f"âŒ å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ‰¹é‡åˆ é™¤keywords metaæ ‡ç­¾...")
    print("=" * 60)
    
    # è·å–æ‰€æœ‰HTMLæ–‡ä»¶
    html_files = glob.glob('*.html')
    
    processed_count = 0
    removed_count = 0
    
    for file_path in html_files:
        # è·³è¿‡å¤‡ä»½ç›®å½•
        if 'backup_' in file_path:
            continue
            
        processed_count += 1
        if remove_keywords_meta_tag(file_path):
            removed_count += 1
            print(f"âœ… {file_path} - keywordsæ ‡ç­¾å·²åˆ é™¤")
        else:
            print(f"â­ï¸  {file_path} - æœªæ‰¾åˆ°keywordsæ ‡ç­¾")
    
    print("=" * 60)
    print(f"ğŸ“Š å¤„ç†å®Œæˆï¼")
    print(f"   - å¤„ç†æ–‡ä»¶æ•°: {processed_count}")
    print(f"   - åˆ é™¤æ ‡ç­¾æ•°: {removed_count}")
    print(f"   - æ¸…ç†ç‡: {removed_count/processed_count*100:.1f}%" if processed_count > 0 else "   - æ¸…ç†ç‡: 0%")

if __name__ == "__main__":
    main()
