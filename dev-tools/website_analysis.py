#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç½‘ç«™æ•´ä½“çŠ¶æ€æ£€æŸ¥è„šæœ¬
æ£€æŸ¥HTMLç»“æ„ã€é“¾æ¥æ ¼å¼ã€æ€§èƒ½ä¼˜åŒ–ç­‰å„æ–¹é¢
"""

import re
import os
from collections import defaultdict

def analyze_website():
    print("ğŸ” ç½‘ç«™æ•´ä½“çŠ¶æ€åˆ†æ")
    print("=" * 60)
    
    # 1. æ£€æŸ¥index.htmlåŸºæœ¬ä¿¡æ¯
    index_file = 'index.html'
    if not os.path.exists(index_file):
        print("âŒ index.html æ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    with open(index_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    print(f"ğŸ“„ index.html æ–‡ä»¶å¤§å°: {len(content):,} å­—ç¬¦")
    print(f"ğŸ“„ index.html è¡Œæ•°: {len(content.splitlines()):,} è¡Œ")
    
    # 2. æ£€æŸ¥HTMLç»“æ„
    print("\nğŸ—ï¸ HTMLç»“æ„æ£€æŸ¥:")
    doctype = re.search(r'<!DOCTYPE[^>]*>', content)
    html_tag = re.search(r'<html[^>]*>', content)
    head_tag = re.search(r'<head>', content)
    body_tag = re.search(r'<body[^>]*>', content)
    
    print(f"   DOCTYPEå£°æ˜: {'âœ…' if doctype else 'âŒ'}")
    print(f"   HTMLæ ‡ç­¾: {'âœ…' if html_tag else 'âŒ'}")
    print(f"   HEADæ ‡ç­¾: {'âœ…' if head_tag else 'âŒ'}")
    print(f"   BODYæ ‡ç­¾: {'âœ…' if body_tag else 'âŒ'}")
    
    # 3. æ£€æŸ¥SEOä¼˜åŒ–
    print("\nğŸ” SEOä¼˜åŒ–æ£€æŸ¥:")
    title = re.search(r'<title[^>]*>(.*?)</title>', content, re.DOTALL)
    meta_desc = re.search(r'<meta[^>]*name=["\']description["\'][^>]*content=["\']([^"\']*)["\']', content)
    meta_keywords = re.search(r'<meta[^>]*name=["\']keywords["\']', content)
    canonical = re.search(r'<link[^>]*rel=["\']canonical["\']', content)
    
    print(f"   æ ‡é¢˜æ ‡ç­¾: {'âœ…' if title else 'âŒ'} {f'({title.group(1)[:50]}...)' if title else ''}")
    print(f"   æè¿°æ ‡ç­¾: {'âœ…' if meta_desc else 'âŒ'}")
    print(f"   å…³é”®è¯æ ‡ç­¾: {'âŒ (å·²æ¸…ç†)' if not meta_keywords else 'âš ï¸ ä»å­˜åœ¨'}")
    print(f"   è§„èŒƒé“¾æ¥: {'âœ…' if canonical else 'âŒ'}")
    
    # 4. æ£€æŸ¥æ€§èƒ½ä¼˜åŒ–
    print("\nâš¡ æ€§èƒ½ä¼˜åŒ–æ£€æŸ¥:")
    dns_prefetch = re.findall(r'<link[^>]*rel=["\']dns-prefetch["\']', content)
    preload = re.findall(r'<link[^>]*rel=["\']preload["\']', content)
    lazy_loading = re.findall(r'loading=["\']lazy["\']', content)
    defer_scripts = re.findall(r'<script[^>]*defer[^>]*>', content)
    
    print(f"   DNSé¢„å–: {'âœ…' if dns_prefetch else 'âŒ'} ({len(dns_prefetch)} ä¸ª)")
    print(f"   èµ„æºé¢„åŠ è½½: {'âœ…' if preload else 'âŒ'} ({len(preload)} ä¸ª)")
    print(f"   å›¾ç‰‡æ‡’åŠ è½½: {'âœ…' if lazy_loading else 'âŒ'} ({len(lazy_loading)} ä¸ª)")
    print(f"   è„šæœ¬å»¶è¿ŸåŠ è½½: {'âœ…' if defer_scripts else 'âŒ'} ({len(defer_scripts)} ä¸ª)")
    
    # 5. æ£€æŸ¥é“¾æ¥æ ¼å¼ä¸€è‡´æ€§
    print("\nğŸ”— é“¾æ¥æ ¼å¼æ£€æŸ¥:")
    all_links = re.findall(r'href=["\']([^"\']*\.html)["\']', content)
    absolute_links = [link for link in all_links if link.startswith('/')]
    relative_links = [link for link in all_links if not link.startswith('/') and not link.startswith('http')]
    external_links = [link for link in all_links if link.startswith('http')]
    
    print(f"   æ€»é“¾æ¥æ•°: {len(all_links)}")
    print(f"   ç›¸å¯¹è·¯å¾„: {'âœ…' if relative_links else 'âŒ'} ({len(relative_links)} ä¸ª)")
    print(f"   ç»å¯¹è·¯å¾„: {'âœ… (æ— )' if not absolute_links else f'âš ï¸ ({len(absolute_links)} ä¸ª)'}")
    print(f"   å¤–éƒ¨é“¾æ¥: {len(external_links)} ä¸ª")
    
    # 6. æ£€æŸ¥å“åº”å¼è®¾è®¡
    print("\nğŸ“± å“åº”å¼è®¾è®¡æ£€æŸ¥:")
    viewport = re.search(r'<meta[^>]*name=["\']viewport["\']', content)
    bootstrap = re.search(r'bootstrap', content, re.IGNORECASE)
    media_queries = re.findall(r'@media[^{]*{', content)
    
    print(f"   è§†å£æ ‡ç­¾: {'âœ…' if viewport else 'âŒ'}")
    print(f"   Bootstrapæ¡†æ¶: {'âœ…' if bootstrap else 'âŒ'}")
    print(f"   åª’ä½“æŸ¥è¯¢: {len(media_queries)} ä¸ª")
    
    # 7. æ£€æŸ¥æ— éšœç¢è®¿é—®
    print("\nâ™¿ æ— éšœç¢è®¿é—®æ£€æŸ¥:")
    aria_labels = re.findall(r'aria-label=["\'][^"\']*["\']', content)
    alt_texts = re.findall(r'alt=["\'][^"\']*["\']', content)
    
    print(f"   ARIAæ ‡ç­¾: {'âœ…' if aria_labels else 'âŒ'} ({len(aria_labels)} ä¸ª)")
    print(f"   å›¾ç‰‡ALTæ–‡æœ¬: {'âœ…' if alt_texts else 'âŒ'} ({len(alt_texts)} ä¸ª)")
    
    # 8. ç»Ÿè®¡æ¸¸æˆæ•°é‡
    print("\nğŸ® æ¸¸æˆå†…å®¹ç»Ÿè®¡:")
    game_links = [link for link in all_links if 'unblocked.html' in link and not link.startswith('http')]
    category_links = [link for link in all_links if 'games.html' in link]
    
    print(f"   æ¸¸æˆé¡µé¢: {len(game_links)} ä¸ª")
    print(f"   åˆ†ç±»é¡µé¢: {len(category_links)} ä¸ª")
    
    # 9. æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
    print("\nğŸ“ æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥:")
    missing_files = []
    for link in relative_links:
        if not os.path.exists(link):
            missing_files.append(link)
    
    print(f"   é“¾æ¥æ­£ç¡®æ€§: {'âœ… 100%' if not missing_files else f'âŒ {len(missing_files)} ä¸ªç¼ºå¤±æ–‡ä»¶'}")
    
    # 10. æ€»ä½“è¯„åˆ†
    print("\nğŸ“Š æ•´ä½“è¯„åˆ†:")
    score = 0
    max_score = 10
    
    # è¯„åˆ†æ ‡å‡†
    if doctype and html_tag and head_tag and body_tag: score += 1
    if title and meta_desc: score += 1
    if not meta_keywords: score += 1  # æ²¡æœ‰keywordsæ˜¯å¥½äº‹
    if dns_prefetch or preload: score += 1
    if lazy_loading: score += 1
    if not absolute_links: score += 1  # é“¾æ¥æ ¼å¼ç»Ÿä¸€
    if viewport: score += 1
    if bootstrap: score += 1
    if aria_labels: score += 1
    if not missing_files: score += 1
    
    percentage = (score / max_score) * 100
    
    if percentage >= 90:
        grade = "ğŸ† ä¼˜ç§€"
    elif percentage >= 80:
        grade = "ğŸ¥ˆ è‰¯å¥½"
    elif percentage >= 70:
        grade = "ğŸ¥‰ ä¸­ç­‰"
    else:
        grade = "âš ï¸ éœ€æ”¹è¿›"
    
    print(f"   å¾—åˆ†: {score}/{max_score} ({percentage:.0f}%)")
    print(f"   ç­‰çº§: {grade}")
    
    print("\nâœ… ç½‘ç«™åˆ†æå®Œæˆ!")

if __name__ == "__main__":
    analyze_website()
